{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajeet/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ajeet/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ajeet/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-ac7693567a98>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ajeet/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ajeet/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:219: retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/ajeet/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/ajeet/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ajeet/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.pad(X_train, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0), (2,2), (2,2), (0,0)), 'constant')\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d6df8d208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2, p=\"SAME\"):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LeNet(x):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # random weights\n",
    "    layer1_w = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6)), mean=mu, stddev=sigma)\n",
    "    layer1_bias = tf.Variable(tf.zeros(6))\n",
    "    \n",
    "    # random bias, input = 32x32x1, out put is 28x28x6\n",
    "    layer1 = tf.nn.bias_add(tf.nn.conv2d(x, layer1_w, strides=[1,1,1,1], padding=\"VALID\"), layer_bias)\n",
    "    # activation\n",
    "    layer1= tf.nn.relu(layer1)\n",
    "    \n",
    "    # maxpooling input = 28, output = 14x14x6\n",
    "    layer1 = maxpool2d(layer1, k=2, p=\"VALID\")\n",
    "    \n",
    "    # input = 14, output = 10x10x16\n",
    "    layer2_w = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16)), mean=mu, stddev=sigma)\n",
    "    layer2_bias = tf.Variable(tf.zeros(16))\n",
    "    layer2 = tf.nn.bias_add(tf.nn.conv2d(layer1, layer1_w, strides=[1,1,1,1]), layer2_bias)\n",
    "    layer2 = tf.nn.relu(layer2)\n",
    "    \n",
    "    # maxpooling, input = 10, output = 5x5x16\n",
    "    layer2 = maxpool2d(layer2, k=2, p=\"VALID\")\n",
    "    \n",
    "    # fully connected layer\n",
    "    fc1_w = tf.Variable(tf.truncated_normal(shape=(400, 120)))\n",
    "    fc1 = flatten()000000000000000001\n",
    "    ............................................................................................................"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
